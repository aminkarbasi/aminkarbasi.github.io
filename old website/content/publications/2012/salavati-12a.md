+++
date = "2012-05-03"
title = "Multi-level error-resilient neural networks"
math = "true"
description = "publication"
publish = "ISIT"
category = "conference"
weight=2
author = "Amir Hesam Salavati, Amin Karbas"
link = "/files/salavati-12.pdf"
keyword1="computational neuroscience"
+++

# Abstract

The problem of neural network association is to retrieve a previously memorized pattern from its noisy version using a network of neurons. An ideal neural network should include three components simultaneously: a learning algorithm, a large pattern retrieval capacity and resilience against noise. Prior works in this area usually improve one or two aspects at the cost of the third. Our work takes a step forward in closing this gap. More specifically, we show that by forcing natural constraints on the set of learning patterns, we can drastically improve the retrieval capacity of our neural network. Moreover, we devise a learning algorithm whose role is to learn those patterns satisfying the above mentioned constraints. Finally we show that our neural network can cope with a fair amount of noise.



